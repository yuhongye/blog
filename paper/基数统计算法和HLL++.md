这是对google的《HyperLogLog in Practice: Algorithm ENgineering of a State of The Art Candinality Estimation Algorithm》的阅读笔记. 首先会介绍LinearCounting和HyperLogLog算法，然后是对论文中各章节的总结.

#0. LC, LLC and HLL

### 0.1 LinearCounting, 空间复杂度O(N)

设一哈希函数H，其哈希空间为m(最小值0，最大值m-1), 并且服从均匀分布。使用一个长度为m的bitmap, 初始值都为0，对于待预估的集合，使用H得到一个值k, bitmap(k) = 1；遍历完整个集合后，得到bitmap中值为0的个数为u, 则n=-mlog(${u} \over {m}$)​为基数的一个估计值，且为最大似然估计。

其空间复杂度为O(Nmax)，大约是使用bitmap的十分之一，该算法的空间复杂度较高，但在元素数据较少的时候表现优异，用来弥补HyperLogLog在元素数较少时预估偏大的缺陷。

### 0.2 LogLogCounting, 空间复杂度O(log2(log2(N))))

LogLogCounting空间复杂度为O(log2(log2(N)))), 使得通过KB级内存预估数亿级别的基数成为可能，目前在处理大数据时基数计算问题时，所采用的算法基本是LLC或其变种。

#### 均匀随机化

首先需要选取一个哈希函数H应用于所有元素，然后对哈希值进行基数估计，H必须满足如下条件:

1. H的结果具有很好的随机性，也就是说无论原始集合元素的值分布如何，其哈希结果的值几乎服从均匀分布（D.Knuth已经证明不可能通过一个哈希函数将一组不服从均匀分布的数据映射为绝对服从均匀分布，但是很多哈希函数可以生成近乎服从均匀分布的结果）
2. H的碰撞几乎可以忽略不计
3. H的结果是固定长度的, 设为L. 这里有一个疑问: 目前主流的hash函数都会把所有位数占满吗?

#### 思想来源

设w是待估集合中某个元素经过hash后得到的值，w可以看做一个固定长度为L的bit串，每个bit的编码分别为1, 2, ...L, 设p(w)为w的bit串中第一次出现1的位置，显然`1<=p(w)<=L`。如果我们遍历集合的全部元素后，取$p_{max}$为所有p(w)中最大的那一个，可以把n=${2^{p_{max}}}$作为基数的一个粗糙估计，根据伯努利过程，可以得到下面两条解释:

1. 如果n 远远小于 ${2^{p_{max}}}$, 那么我们得到$p_{max}$为当前值的概率几乎为0
2. 如果n 远远大于 ${2^{p_{max}}}$, 那么我们得到$p_{max}$为当前值的概率也几乎为0

因此可以把${2^{p_{max}}}$作为基数的一个粗糙估计

#### 分桶平均

如果直接使用上面的单一估计量进行基数估计，会由于偶然性导致较大的误差，LLC采用了分桶平均的思想来消除误差。具体来说就是:
1. 将哈希空间分成m份，每份称之为一个桶(bucket)，哈希值w的前p位用来标识桶，则m=$2^p$
2. 剩下的L-p位作为基数估计的比特串，得到每个桶的$p_{max}$
3. $p_{max}$ = 全部桶的$p_{max}$的均值, n = ${2^{p_{max}}}$
4. 偏差修正, ${2^{p_{max}}}$是一个粗糙估计，需要修正，修正后的结果：n = $a_m{2^{p_{max}}}$, 其中${a_m}$=xxx
5. 误差分析，LLC的错误率为: $ 1.3 \over \sqrt{m}$
6. 内存使用分析，m个桶，则每个桶存储$p_{max}$时最多需要：registers = log(L-p) bit,  内存使用量为: mlog(L-p)

LLC算法的优势是内存使用较少，不过当基数较少时，估计误差过大，因此实际使用时都是使用的LLC的改进算法。

### 0.3 HyperLogLog

#### 对LLC的改进

##### 使用调和平均数

HLLC的第一个改进是使用调和平均数替代几何平均数。注意LLC是对各个桶取算数平均数，而算数平均数最终被应用到2的指数上，所以总体来看LLC取得是几何平均数。由于几何平均数对于离群值（例如这里的0）特别敏感，因此当存在离群值时，LLC的偏差就会很大，这也从另一个角度解释了为什么n不太大时LLC的效果不太好。这是因为n较小时，可能存在较多空桶，而这些特殊的离群值强烈干扰了几何平均数的稳定性。

改进后的预估公式：$\hat{n}=\frac{\alpha_m m^2}{\sum{2^{-M}}}$, $\alpha_m=(m\int _0^\infty (log_2(\frac{2+u}{1+u}))^m du)^{-1}$

##### 分段偏差纠正

在HLLC的论文中，作者在实现建议部分还给出了在n相对于m较小或较大时的偏差修正方案。具体来说，设E为估计值：

1. 当${E<={5 \over 2} m}$时，使用LC进行估计。

2. 当${{5 \over 2} m}<E≤{1 \over 30} {2^{32}}$，使用上面给出的HLLC公式进行估计。

3. 当$E>{1 \over 30} {2^{32}}$，估计公式如为n̂ = $-2^{32}log(1-E/2^{32})$

#### 误差分析和内存分析

Error = ${1.04 \over \sqrt{m}}$, 比LLC的$ 1.3 \over \sqrt{m}$要低，内存占用量同LLC。

