这里说的是应用层面的缓存算法，不包括CPU cache.

# 1. LRU(Least Recently Used)
Discards the least recently used item, 也就是删除最长时间未使用，可以理解成是按照timestamp排序，删除timestamp最小的那个。比如缓存大小为3， 插入的顺序为A, B, C, A, D, 缓存中的变化如下:

```java
初始插入A, B, C     更新A时，不会替换       插入D时，替换掉最老的B
不会发生替换         A 变成最新
-----                -----                -----
| C |                | A |                | D |
-----                -----                -----
| B |   ---->        | C |     ---->      | A |
-----                -----                -----
| A |                | B |                | C |
-----                -----                -----
```

### 简单实现
`Map`就是一个天然的cache，只不过它没有替换算法，我们来思考如何给`Map`加上`LRU`算法。`LRU`算法的核心: 按照元素的访问(put, get, update)顺序排序，当访问一个元素时，就把该元素放到队列的开头，如果空间耗尽, 则删除队尾的元素。

__思路__: 使用`Map`来保存数据, 使用双向链表来保存访问顺序
```java
------     ------
| K1 | --> | V1 |
------     ------
            ^  |  
            |  V
------     ------
| K2 | --> | V2 |
------     ------
            ^  |  
            |  V
------     ------
| K3 | --> | V3 |
------     ------
            ^  |  
            |  V
------     ------
| Kn | --> | Vn |
------     ------
```

`Map`中的`value`应该包括哪些内容：
 
 * value, 这是缓存的数据
 * next, prev 指针，用来维护链表结构
 * key, 为什么需要key? 在删除队尾元素时，需要拿到该元素的key，然后调用`map.remove(key)`

 示例代码如下：
 ```java
 /**
  * 双向链表中的Node, 也是Map中的value
  * 空间浪费: Node对象头 + 3个对象引用(key, next, prev), value本来也应该被放到map中，所以在这里不算浪费
  */
class Node<K, V> {
    K key;
    V value;
    // 指向下一个元素
    Node<K, V> next;
    // 指向前一个元素
    Node<K, V> prev;
}

class LRU<K, V> {
    // 缓存的最大容量
    private int capacity;
    Map<K, Node<K, V>> cache;
   
   // head插入时使用，tail删除时使用，同时也用作了哨兵，省去了很多null判断
   Node<K, V> head = new Node<>(null, null);
   Node<K, V> tail = new Node<>(null, null);
   /**
    * 删除时: tail.prev
    *  --------     --------     --------
    *  |      | --> |      | --> |      |
    *  | head | <-- |      | <-- | tail |
    *  --------     --------     --------
    */
   {
       head.next = tail;
       tail.prev = head;
   }

   /**
    * 如果key已经存在，则需要把key放到队头，表示最新访问过的元素
    */
   public V get(K key) {
       Node<K, V> node = cache.get(key);
       if (node != null) {
           putFirst(node);
           return node.value;
       }
       return null;
   }

   /**
    * 如果key不存在，判断是否需要删除队尾元素，然后put，并放到队头
    * 如果key已经存在, 更新value, 移动到队头
    */
   public void put(K key, V value) {
       Node<K, V> node = cache.get(key);
       if (node != null) {
           node.value = value;
           putFirst(node);
       } else {
           node = new Node(key, value);
           // 没有空间，需要驱逐最后访问的node
           if (cache.size() >= capacity) {
               removeLast();
           }
           cache.put(key, node);
           putFirst(node);
       }
   }
}
 ```

缺点： sparse burst: 连续访问新元素导致整个缓存被清空，比如Cache的size为n，在某个时间段内，连续的n个不重复请求会把Cache的数据替换一遍。

 ### 问题
 1. 如何在多线程下实现高效的缓存?
    
    简单的实现要求每次操作都要加锁，很难高效的在多线程下实现。
 2. 如何更加节省内存?

# 2. LFU Least Frequently Used
统计每个item被访问的次数，当发生替换时，删除掉被访问次数最少的元素。假设缓存大小为3, 演示如下：
```java
访问序列    cache的结构: data:count
           -------
A          | A:1 |
           -------
A          | A:2 |
           -------
A          | A:3 |
           -------
A          | A:4 |
           -------------
B          | A:4 | B:1 |
           -------------------
C          | A:4 | B:1 | C:1 |
           -------------------
D          | A:4 | B:1 | D:1 | 删除最少被访问的C
           -------------------
C          | A:4 | B:1 | C:1 | 删除最少被访问的D
           -------------------
B          | A:4 | B:2 | C:1 |
           -------------------
D          | A:4 | B:2 | D:1 | 删除最少被访问的C
           -------------------
C          | A:4 | B:2 | C:1 | 删除最少被访问的D
           -------------------
D          | A:4 | B:2 | D:1 | 删除最少被访问的C
           -------------------
```
在上面的演示中，A最开始被访问了4次，然后就再也没有访问了，但是它却始终留在缓存中。C和D在后面连续的访问，却也连续的被置换出去，缓存命中率太低。由此，我们可以得到LFU的两个缺点：

1. 某些最初被大量访问而后续不会再被访问的item, 会留在缓存中
2. 新加入的元素由于访问量小，可能会被最先置换出去。又由于局部性原理，新加入的元素很可能很快被再次访问。

简单实现参考LRU，可以使用DoubleLinkedList，每次有访问时，增加它的`count`, 使用插入排序的思想，往前移动到正确的位置。