学习技术应该从基础开始， 基础决定了高度和效率。

# 0. 硬件基础

### 1. 体系结构

在理解并发编程中，我们主要关注3个组件：

* 处理器：执行软件线程的硬件设备，通常线程数要比处理器数多，因此每个处理器运行一个线程一段时间后将它放置在一遍，转而去执行别的线程
* Interconnect：处理器与处理器，处理器与存储器之间的媒介
* 存储器：现代存储器是一个层次结构，从缓存一直到主存

#### 两种互连结构

![体系结构](/Users/caoxiaoyong/Documents/document/blog/images/java/并发硬件基础.png)

#### SMP(Symmetric Multiprocessor, 对称多处理器)

###### 通过Bus互连

处理器和内存之间使用__总线__互连，类似微型以内网上的广播媒介，处理器和内存都有用来负责发送和监听总线上广播的信息的总线控制单元，在任一时刻只能有一个处理器或存储控制器在总线上广播。这种结构易于构建，但是扩展性较差，因为总线最终会过载，理解这一点很重要，在SMP结构中，总线是一种稀缺资源。

###### 多核结构

我们现在用的计算机更多的是多核处理器，比如个人pc上只有一个cpu，每个cpu包含多个核，其中cache放在芯片内部，cache也是分层的，有核内缓存和cpu所有核共享的缓存，比如以intel的cpu为例，所有核共现L3缓存。在同一个cpu中有共享的缓存，那么多个核之间就可以通过共享的L3 cache来进行高效通信，不过依然是需要缓存一致性协议的。

###### 缓存一致性协议MESI

MESI将缓存中的cache line分成4类：

* Modified: 数据已修改，需要同步到主存
* Exclusive: 独占，但是cache line是干净的，随时可以修改
* Shared: 共享的，cache line是干净的，不能修改
* Invalid: cache line是空的

缓存一致性协议是复杂的，这里不做过多讨论。

###### Store Buffer

当处理器修改了某个值，对象的cache line被标记为dirty，且需要同步到主存中。在现代处理器中，写请求并不是直接作用到主存，而是请写请求收集到Store Buffer的硬件队列中，对CPU而言写入到Store Buffer中写操作就算完成了，如果Store Buffer中没有空白空间，则CPU必须等待。使用Store Buffer有两个好处：

* 批处理：将一批写请求发布出去，更加高效
* 写合并：对一个地址的多次写只用同步主存一次

这样会产生一个后果：CPU以为已经完成的写操作还没有同步到主存，别的CPU读到的可能依然是旧值。比如下面的时间顺序：

1. CPU1将flag写入到Store Buffer中
2. CPU2读取flag的值，它只能从主存读取
3. CPU1中的Store Buffer flush到主存

我们可以看到CPU2读到的是旧值，为了能看到flag的最新值，CPU2需要使用内存屏障来刷新CPU1的Store Buffer，以确保所有在内存屏障指令前的写操作对CPU2都是可见的。关于内存屏障后面会单独介绍。

##### cc-NUMA 现代大多都是带缓存的NUMA

#### 自旋：反复的读取本地cache中的值而不是反复地使用总线是设计高效自旋的关键

如果每次判断值是否发生变化都需要从内存中读取，则需要不停的在总线上发送消息，这会消耗总线带宽但是却没有做任何有用的工作，由于总线是广播媒介，这些直接对内存的请求可能会阻止其他处理器的推进。因此对于无告诉缓存的SMP系统结构来说，自旋是一种非常糟糕的行为。

而对于有cache的SMP或者NUMA结构，自旋消耗的资源非常少：只在第一次读地址时产生一次cache miss，后续只要数据没有变化就一直读cache，而不占用总线资源。因此反复读cache中的值是设计高效自旋的关键。

### Memory Barrier

现代多处理器通常不提供顺序一致的存储器：

* 编译器为了提高性能，会进行指令重排
* 多处理器硬件本身的写操作并不是立即在Memory中生效，一般都是写到存储缓冲区中，只有在需要时才写入到内存中

###### 对于Memory Barrier的使用

1. Memory Barrier使用代价较高，因此只有在必要时才使用
2. 同步问题很难追踪，因此也应该(在必须要的时候)充分地使用Memory Barrier，而不是依靠特定的的平台来保证对内存指令同步的限制。

# 1. 并发结构

### 自旋锁和争用

底层硬件是提供了同步原语的，比如CAS和LL/SC，由于下面示例都使用Java代码编写，默认使用concurrent.atomic包下的原子类提到底层硬件的CAS能力。

##### 1. Test-And-Set和Test-Test-And-Set

下面有两个锁的实现，其语义都是正确的：依赖于一个共享变量state，其中true表示锁被占用，false表示锁空闲。每个线程原子的尝试去修改它，如果在修改的时候state==false，并且原子修改成功，则表示获取锁成功。

```java
class TASLock implements Lock {
  // 初始时锁是空闲的
  AtomicBoolean state = new AtomicBoolean(false);
  
  public void lock() {
    // 修改state的状态，如果在修改之前锁是空闲的并且修改成功，则获取锁成功
    // 否则自旋，直到获取锁
    while (state.getAndSet(true));
  }
  
  public void unlock() {
    // 释放锁
    state.set(false);
  }
}
```

这个锁是低效的，它会同时占用总线带宽和使别的处理器缓存失效：

1. 每次循环会尝修改state的值，它会在总线上发布广播，这会延迟所有的线程，包括没有打算获取锁的其他线程
2. 更严重的是，它会使别的处理器的对state的cache失效，使得每次都得从内存读取
3. 持有锁的线程想释放锁，也会被别的一直在自旋的线程delay，因为它们一直在总线上发布广播

针对上述问题的一个优化是：只在本地缓存中自旋。

```java
class TTASLock extends TASLock {
  public void lock() {
    while (true) {
      // 只在本地缓存中的值上自旋，不占用总线，也不尝试修改state导致其他处理器的缓存失效
      while (state.get());
      // 只有在确定锁的状态发生了变化，有可能获取锁的情况下才去尝试修改
      // 这个时候会发生争用，修改可能会失败
      if (! state.getAndSet(true)) {
        return;
      }
    }
  }
}
```

相比于TASLock, TTASLock要高效的多，但是它也有缺陷：当锁空闲时，所有锁都停止自旋，几乎在同一时间尝试获取锁，这会造成高争用。

但是它们释放锁的方法并不高效，原因如下：

1. 当持有锁的线程释放锁时会修改state的状态
2. 所有其他线程的cache马上失效，它们几乎在同一时间去读取内存，并尝试修改state的值，这会引起一场总线风暴。同时这个地方也是高争用发生的地方
3. 第一个成功获取锁的线程会修改state状态，其他线程又必须重新从内存中读取state的值，这又会引起一次总线风暴

### 2. 队列锁

上面的TTASLock问题在于所有的线程在共享的存储单元上旋转，每一次成功的获取锁都会有可能会引发一场总线风暴。因此优化方向是：__每个线程在不同的存储单元上旋转__，一次只有一个存储单元上的线程能获取到锁，当它释放锁时，它会唤醒在下一个存储单元上自旋的线程。

##### 1. 数组锁：线程个数不能超过已知的最大值n

```java
public class AndersonLock implements Lock {
  // 同时争夺这把锁的最大线程数，如果超过了这个数，则锁失效
  int size;
  // 每个线程在一个slot上自旋，如果slot上的值为true，表示锁可用，否则自旋
  volatile boolean[] states;
  // 下一个可用的slot位置：线程会在该slot上自旋
  AtomicInteger tail;
  
  // 当前线程自旋的位置
  ThreadLocal<Integer> mySlot = ThreadLocal.withInitial(() -> 0);
  
  public AdersonLock(int n) {
    this.size = n;
    states = new boolean[size];
    tail = new AtomicInteger(0);
    
    // 初始时锁是可用的，第一个达到的线程可以直接拿到锁
    states[0] = true;
  }
  
  public void lock() {
    // 获取可用的slot
  	int slot = tail.getAndIncrement() % size;
    mySlot.set(slot);
    
    // 自旋直到锁可用，可用之后就只有自己能获取到锁，因此不会有争用
    while (!states[slot]);
  }
  
  public void unlock() {
    int slot = mySlot.get();
    states[slot] = false;
    // 唤醒在下一个位置自旋的线程，如果无，则锁空闲，下一个到来的线程可以直接获取锁
    states[(slot+1) % size] = true;
  } 
}
```

可以看到数组锁没有争用，当锁释放时只有一个线程会被唤醒。同时需要注意false share问题，可以采用填充让每个slot占用一个cache line。

数组锁的问题在于空间效率低，必须要创建n个slot，而且获取锁的线程不能超过n，否则锁失效。

##### 2. CLH队列锁: 虚拟队列，在前驱节点上自旋。因为是虚拟队列，所以释放锁时只能修改自己的状态，而不能直接修改后继节点的状态，所以后继节点只能在前驱节点上自旋

CLH队列锁使用队列来解决的空间问题，它的队列是虚拟的:

1. 每个线程到来之后创建一个node，其中node.pending表示线程是否在等待锁或者已经持有了锁，false表示已经释放了锁，把锁的许可传给了下一个线程
2. 每个线程在它的pred node上自旋，因此在NUMA架构中它的性能很低
3. 当它释放锁时，后序节点还在它的node上自旋，不能对复用它自身的node，但是它的pred是空闲，直接复用它的pred.node

```java
public class CLHLock extends ALock {
    AtomicReference<QNode> tail;

    ThreadLocal<QNode> myPred;
    ThreadLocal<QNode> myNode;

    public CLHLock() {
        // 初始时锁是空闲的，tail.pending = false, 第一个到来的线程可以马上获得锁
        tail = new AtomicReference<>(new QNode());
        myNode = ThreadLocal.withInitial(() -> new QNode());
        // 初始时还没有pred
        myPred = ThreadLocal.withInitial(() -> null);
    }

    @Override
    public void lock() {
        QNode node = myNode.get();
        node.pending = true;
        // 加到队尾
        QNode pred = tail.getAndSet(node);
        myPred.set(pred);

        // 在前一个节点上pending，这一步会导致在NUMA机器上比较低效，因为不是在本地缓存上自旋
        while (pred.pending);
    }

    @Override
    public void unlock() {
        QNode node = myNode.get();
        // 释放锁，唤醒下一个在pending的线程
        node.pending = false;
        /**
         * 论文中的原话: The difficulty is that a thread cannot know when the Node it has granted is no longer being
         * watched by anthor thread and can be reused.
         * 这句话的意思是想复用QNode，但是队列中的下一个线程又在myNode上自旋，因此没办法直接复用。
         *
         * 假设不复用前一个节点, 考虑如下场景：
         *   time | thread1                    | thread2
         *   -----|---------------------------|----------------------------
         *     t1 | 释放锁，pending=false      |在node1.pending上自旋
         *     t2 | 马上获取锁,pending=true,   | 依然在自旋
         *         并且加入到队列尾部，在node2. |
         *         pending上自旋
         *
         *  thread1和thread2死锁了
         *
         *  但是它的前一个节点是完全空闲的，可以直接复用
         */
        myNode.set(myPred.get());
    }

    static class QNode {
        private long p1, p2, p3, p4, p5, p6, p7, p8;
        /**
         * 锁的状态有两种：
         *  - pending: 表示在等待锁或者已经获取了锁
         *  - granted: 表示已经成功的释放了锁，把锁的许可传给了下一个线程
         *  因此我们这里通过一个boolean来表示是否pending
         */
        volatile boolean pending;
        private long p11, p12, p13, p14, p15, p16, p17, p18;
    }
```

自旋锁不适用于高争用的场景，如果把CLHLock用在10个活跃的线程持续获取锁的情况下，性能会很低，因为大家都不愿意放弃cpu，一直在自旋，有可能导致获取到锁的线程反而被调度出去。     

#### 3. MCS队列锁：显式队列，在自己节点上自旋。因为是显式队列，所以可以操作后继节点的状态

```java
public class MCSLock extends ALock {
    // 链表的尾部，每次都是从这里插入
    private AtomicReference<QNode> tail = new AtomicReference<>(null);

    private ThreadLocal<QNode> myNode = ThreadLocal.withInitial(() -> new QNode());

    /**
     * 每次获取锁的时候需要把自己插入到队列尾部
     */
    @Override
    public void lock() {
        QNode node = myNode.get();
        node.pending = true;
        // 插入到队列中
        QNode pred = tail.getAndSet(node);
        if (pred != null) {
            pred.next = node;

            // 在自己节点上自旋
            while (node.pending);
        }
    }

    /**
     * 释放锁时需要从队列中断开
     */
    @Override
    public void unlock() {
        QNode node = myNode.get();
        assert node.pending ==  false;
        // 没有其他的线程等待锁, 自己是队列尾部
        if (node.next == null) {
            if (tail.compareAndSet(node, null)) {
                return;
            }
            // 如果修改tail失败，说明目前已经有一个线程到来了，它已经变成了队尾，但是还没有连接上
            // 等待这个线程执行pred.next = node;
            while (node.next == null);
        }
        node.next.pending = false;
        // 从队列中断开，方便下次获取锁时重新加入到队列中
        node.next = null;
    }

    static class QNode {
        /**
         * 状态有两种：
         *  - pending: 正在等待锁
         *  - granted: 前驱节点把锁许可给了自己
         */
        volatile boolean pending;

        // 需要volatile修饰吗？
        volatile QNode next;
    }
}
```

MCSLock的优点：

1. 每次释放锁时，它只会使其后继节点的cache失效，因此适用在NUMA架构上
2. 跟CLHLock一样，节点可以复用

缺点：

1. CAS指令调用较多，在CLHLock中只有把节点加入到队列尾部时调用，而在MCSLock中最后一个线程释放锁时还需要额外调用一次
2. 在释放锁时有可能自旋



# 2. 原子类

