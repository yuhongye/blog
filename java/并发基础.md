学习技术应该从基础开始， 基础决定了高度和效率。

# 0. 硬件基础

### 1. 体系结构

在理解并发编程中，我们主要关注3个组件：

* 处理器：执行软件线程的硬件设备，通常线程数要比处理器数多，因此每个处理器运行一个线程一段时间后将它放置在一遍，转而去执行别的线程
* Interconnect：处理器与处理器，处理器与存储器之间的媒介
* 存储器：现代存储器是一个层次结构，从缓存一直到主存

#### 两种互连结构

![体系结构](/Users/caoxiaoyong/Documents/document/blog/images/java/并发硬件基础.png)

#### SMP(Symmetric Multiprocessor, 对称多处理器)

###### 通过Bus互连

处理器和内存之间使用__总线__互连，类似微型以内网上的广播媒介，处理器和内存都有用来负责发送和监听总线上广播的信息的总线控制单元，在任一时刻只能有一个处理器或存储控制器在总线上广播。这种结构已于构建，但是扩展性较差，因为总线最终会过载，理解这一点很重要，在SMP结构中，总线是一种稀缺资源。

###### 多核结构

我们现在用的计算机更多的是多核处理器，比如个人pc上只有一个cpu，每个cpu包含多个核，其中cache放在芯片内部，cache也是分层的，有核内缓存和cpu所有核共享的缓存，比如以intel的cpu为例，所有核共现L3缓存。在同一个cpu中有共享的缓存，那么多个核之间就可以通过共享的L3 cache来进行高效通信，不过依然是需要缓存一致性协议的。

###### 缓存一致性协议MESI

MESI将缓存中的cache line分成4类：

* Modified: 数据已修改，需要同步到主存
* Exclusive: 独占，但是cache line是干净的，随时可以修改
* Shared: 共享的，cache line是干净的，不能修改
* Invalid: cache line是空的

缓存一致性协议是复杂的，这里不做过多讨论。

###### Store Buffer

当处理器修改了某个值，对象的cache line被标记为dirty，且需要同步到主存中。在现代处理器中，写请求并不是直接作用到主存，而是请写请求收集到Store Buffer的硬件队列中，对CPU而言写入到Store Buffer中写操作就算完成了，如果Store Buffer中没有空白空间，则CPU必须等待。使用Store Buffer有两个好处：

* 批处理：将一批写请求发布出去，更加高效
* 写合并：对一个地址的多次写只用同步主存一次

这样会产生一个后果：CPU以为已经完成的写操作还没有同步到主存，别的CPU读到的可能依然是旧值。比如下面的时间顺序：

1. CPU1将flag写入到Store Buffer中
2. CPU2读取flag的值，它只能从主存读取
3. CPU1中的Store Buffer flush到主存

我们可以看到CPU2读到的是旧值，为了能看到flag的最新值，CPU2需要使用内存屏障来刷新CPU1的Store Buffer，以确保所有在内存屏障指令前的写操作对CPU2都是可见的。关于内存屏障后面会单独介绍。

##### cc-NUMA 现代大多都是带缓存的NUMA

#### 自旋：反复的读取本地cache中的值而不是反复地使用总线是设计高效自旋的关键

如果每次判断值是否发生变化都需要从内存中读取，则需要不停的在总线上发送消息，这会消耗总线带宽但是却没有做任何有用的工作，由于总线是广播媒介，这些直接对内存的请求可能会阻止其他处理器的推进。因此对于无告诉缓存的SMP系统结构来说，自旋是一种非常糟糕的行为。

而对于有cache的SMP或者NUMA结构，自旋消耗的资源非常少：只在第一次读地址时产生一次cache miss，后续只要数据没有变化就一直读cache，而不占用总线资源。因此反复读cache中的值是设计高效自旋的关键。

### Memory Barrier

现代多处理器通常不提供顺序一致的存储器：

* 编译器为了提高性能，会进行指令重排
* 多处理器硬件本身的写操作并不是立即在Memory中生效，一般都是写到存储缓冲区中，只有在需要时才写入到内存中

###### 对于Memory Barrier的使用

1. Memory Barrier使用代价较高，因此只有在必要时才使用
2. 同步问题很难追踪，因此也应该(在必须要的时候)充分地使用Memory Barrier，而不是依靠特定的的平台来保证对内存指令同步的限制。

# 1. 并发结构

### 自旋锁和争用

底层硬件是提供了同步原语的，比如CAS和LL/SC，由于下面示例都使用Java代码编写，默认使用concurrent.atomic包下的原子类提到底层硬件的CAS能力。

##### 1. Test-And-Set和Test-Test-And-Set

下面有两个锁的实现，其语义都是正确的：依赖于一个共享变量state，其中true表示锁被占用，false表示锁空闲。每个线程原子的尝试去修改它，如果在修改的时候state==false，并且原子修改成功，则表示获取锁成功。

```java
class TASLock implements Lock {
  // 初始时锁是空闲的
  AtomicBoolean state = new AtomicBoolean(false);
  
  public void lock() {
    // 修改state的状态，如果在修改之前锁是空闲的并且修改成功，则获取锁成功
    // 否则自旋，直到获取锁
    while (state.getAndSet(true));
  }
  
  public void unlock() {
    // 释放锁
    state.set(false);
  }
}
```

这个锁是低效的，它会同时占用总线带宽和使别的处理器缓存失效：

1. 每次循环会尝修改state的值，它会在总线上发布广播，这会延迟所有的线程，包括没有打算获取锁的其他线程
2. 更严重的是，它会使别的处理器的对state的cache失效，使得每次都得从内存读取
3. 持有锁的线程想释放锁，也会被别的一直在自旋的线程delay，因为它们一直在总线上发布广播

针对上述问题的一个优化是：只在本地缓存中自旋。

```java
class TTASLock extends TASLock {
  public void lock() {
    while (true) {
      // 只在本地缓存中的值上自旋，不占用总线，也不尝试修改state导致其他处理器的缓存失效
      while (state.get());
      // 只有在确定锁的状态发生了变化，有可能获取锁的情况下才去尝试修改
      // 这个时候回发生争用，修改可能会失败
      if (! state.getAndSet(true)) {
        return;
      }
    }
  }
}
```

相比于TASLock, TTASLock要高效的多，但是它也有缺陷：当锁空闲时，所有锁都停止自旋，几乎在同一时间尝试获取锁，这会造成高争用。

但是它们释放锁的方法并不高效，原因如下：

1. 当持有锁的线程释放锁时会修改state的状态
2. 所有其他线程的cache马上失效，它们几乎在同一时间去读取内存，并尝试修改state的值，这会引起一场总线风暴。同时这个地方也是高争用发生的地方
3. 第一个成功获取锁的线程会修改state状态，其他线程又必须重新从内存中读取state的值，这又会引起一次总线风暴

